{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8560dbc7",
   "metadata": {},
   "source": [
    "# Linear Regression from First Principles  \n",
    "## Stellar Luminosity as a Function of Mass\n",
    "- Student: Juan José \n",
    "- Class: AREP\n",
    "\n",
    "In this notebook we model stellar luminosity as a function of stellar mass using\n",
    "a linear regression model implemented from first principles. No machine learning\n",
    "libraries are used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f63e52e",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d912743",
   "metadata": {},
   "source": [
    "## Definition of the Stellar Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stellar mass (solar masses)\n",
    "M = np.array([0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4])\n",
    "\n",
    "# Stellar luminosity (solar luminosities)\n",
    "L = np.array([0.15, 0.35, 1.00, 2.30, 4.10, 7.00, 11.2, 17.5, 25.0, 35.0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b79c0",
   "metadata": {},
   "source": [
    "## Dataset Visualization: Luminosity vs Stellar Mass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0686c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(M, L)\n",
    "plt.xlabel(\"Stellar Mass (M⊙)\")\n",
    "plt.ylabel(\"Luminosity (L⊙)\")\n",
    "plt.title(\"Stellar Luminosity vs Mass\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b0013",
   "metadata": {},
   "source": [
    "The relationship is clearly nonlinear, but a linear model provides a first-order\n",
    "approximation to the mass–luminosity relation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed770f",
   "metadata": {},
   "source": [
    "## Linear Model and Mean Squared Error Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23473fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(M, w, b):\n",
    "    return w * M + b\n",
    "\n",
    "def mse(actual, predicted):\n",
    "    return np.mean((actual - predicted)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fca84",
   "metadata": {},
   "source": [
    "## Cost Function Surface over Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_vals = np.linspace(-20, 30, 100)\n",
    "b_vals = np.linspace(-20, 20, 100)\n",
    "\n",
    "W, B = np.meshgrid(w_vals, b_vals)\n",
    "J = np.zeros_like(W)\n",
    "\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[1]):\n",
    "        pred = predict(M, W[i,j], B[i,j])\n",
    "        J[i,j] = mse(L, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080508b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(W, B, J, levels=50)\n",
    "plt.xlabel(\"w\")\n",
    "plt.ylabel(\"b\")\n",
    "plt.title(\"Cost Function J(w, b)\")\n",
    "plt.colorbar(label=\"MSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadd8cb",
   "metadata": {},
   "source": [
    "The minimum of the cost surface corresponds to the optimal parameters that best\n",
    "fit the data in the least-squares sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495e568",
   "metadata": {},
   "source": [
    "## Analytical Derivation of the Loss Gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b74e6",
   "metadata": {},
   "source": [
    "The gradients of the MSE loss are:\n",
    "\n",
    "∂J/∂w = (2/N) Σ (L̂ᵢ − Lᵢ) Mᵢ  \n",
    "∂J/∂b = (2/N) Σ (L̂ᵢ − Lᵢ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36288dc8",
   "metadata": {},
   "source": [
    "## Gradient Computation Using Explicit Loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5eab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_loop(M, L, w, b):\n",
    "    N = len(M)\n",
    "    grad_w = 0.0\n",
    "    grad_b = 0.0\n",
    "\n",
    "    for i in range(N):\n",
    "        pred = w * M[i] + b\n",
    "        error = pred - L[i]\n",
    "        grad_w += error * M[i]\n",
    "        grad_b += error\n",
    "\n",
    "    grad_w = (2/N) * grad_w\n",
    "    grad_b = (2/N) * grad_b\n",
    "    return grad_w, grad_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a7a9b5",
   "metadata": {},
   "source": [
    "## Vectorized Gradient Computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_vectorized(M, L, w, b):\n",
    "    N = len(M)\n",
    "    pred = predict(M, w, b)\n",
    "    error = pred - L\n",
    "    grad_w = (2/N) * np.sum(error * M)\n",
    "    grad_b = (2/N) * np.sum(error)\n",
    "    return grad_w, grad_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f76428",
   "metadata": {},
   "source": [
    "## Gradient Descent Training Procedure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(M, L, alpha=0.01, iterations=500):\n",
    "    w, b = 0.0, 0.0\n",
    "    loss_hist = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        pred = predict(M, w, b)\n",
    "        loss_hist.append(mse(L, pred))\n",
    "\n",
    "        grad_w, grad_b = gradients_vectorized(M, L, w, b)\n",
    "        w -= alpha * grad_w\n",
    "        b -= alpha * grad_b\n",
    "\n",
    "    return w, b, loss_hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a5609",
   "metadata": {},
   "source": [
    "## Convergence Analysis for Different Learning Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.05]\n",
    "\n",
    "for alpha in alphas:\n",
    "    w, b, loss_hist = train(M, L, alpha)\n",
    "    print(f\"α={alpha}: w={w:.3f}, b={b:.3f}, final_loss={loss_hist[-1]:.3f}\")\n",
    "    plt.plot(loss_hist, label=f\"α={alpha}\")\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Convergence for Different Learning Rates\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ba4a5",
   "metadata": {},
   "source": [
    "## Final Model Fit and Systematic Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, _ = train(M, L, alpha=0.01)\n",
    "\n",
    "M_line = np.linspace(min(M), max(M), 100)\n",
    "L_line = predict(M_line, w, b)\n",
    "\n",
    "plt.scatter(M, L, label=\"Data\")\n",
    "plt.plot(M_line, L_line, color=\"red\", label=\"Linear Fit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc0c269",
   "metadata": {},
   "source": [
    "## Conceptual and Astrophysical Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a991ad",
   "metadata": {},
   "source": [
    "**Astrophysical meaning of w:**  \n",
    "It represents the average increase in luminosity per unit stellar mass.\n",
    "\n",
    "**Why is the linear model limited?**  \n",
    "The stellar mass–luminosity relationship is fundamentally nonlinear and cannot\n",
    "be captured accurately by a linear model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
